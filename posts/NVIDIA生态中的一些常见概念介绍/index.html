<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="NVIDIA生态中的一些常见概念介绍#1. 背景#对NVIDIA全系产品常见概念进行简单梳理，以便了解各架构发展历程、显卡算力及引擎开发可能涉及的库。
2. 概念区分#概念区分 加速卡，Product级别概念，如V100卡，3080Ti卡 GPU，Chip级别概念，如V100卡搭载的是GV100的GPU芯片 CUDA 英伟达的并行计算平台和应用程序编程接口（API）模型。 CUDA-X CUDA-X AI 是软件加速库的集合。这些库建立在 CUDA® （NVIDIA 的开创性并行编程模型）之上，提供对于深度学习、机器学习和高性能计算 (HPC) 必不可少的优化功能。这些库包括 cuDNN（用于加速深度学习基元）、cuML（用于加速数据科学工作流程和机器学习算法）、NVIDIA® TensorRT™（用于优化受训模型的推理性能）、cuDF（用于访问 pandas 之类的数据科学 API）、cuGraph（用于在图形上执行高性能分析），以及超过 13 个的其他库。 CUDA Core nvidia GPU的处理器核心或叫像素管道。相同架构下的GPU，越多的CUDA Core代表着越高的性能。什么是架构，有哪些架构，本文有详细说明。GPU架构与CUDA Core的数量一样重要，更先进的架构的加速卡，不一定比用了老架构的卡更快，比如T4就不如V100。 Stream Processor AMD家的“CUDA Core”。不能将 CUDA Core和Stream Processer等同起来，两者功能相似，但是不可比。 Tensor Core Nvidia在其Volta架构中引入了Tensor Core这一特殊功能单元，使得Tesla V100的峰值吞吐率可以达到Tesla P100 32位浮点吞吐率的12倍，开发者也可以利用混合精度在不牺牲精度的情况下达到更高的吞吐率。 自Volta架构首次推出 Tensor Core 技术到目前（07）的Hoper架构以来，NVIDIA GPU 的峰值性能提高了 60 倍。 TFFLOPS 一个TFLOPS（teraFLOPS）等于每秒一万亿（=10^12）次的浮点运算。 NVLINK 高速互联技术，2016年随Pascal GP100 GPU和Tesla P100加速器一起推出。 与PCIe互联技术相比，可以提供GPU之间GPU和CPU之间更高速的传输性能。 GDDR6 第六版图形用双倍资料传输率（Graphics Double Data Rate, version 6，简称GDDR6）是一种高带宽的显示存储器标准，用于显卡、游戏终端以及高性能运算上。 各个Tensor Core架构支持的精度类型 3.">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="" />
<meta property="og:description" content="NVIDIA生态中的一些常见概念介绍#1. 背景#对NVIDIA全系产品常见概念进行简单梳理，以便了解各架构发展历程、显卡算力及引擎开发可能涉及的库。
2. 概念区分#概念区分 加速卡，Product级别概念，如V100卡，3080Ti卡 GPU，Chip级别概念，如V100卡搭载的是GV100的GPU芯片 CUDA 英伟达的并行计算平台和应用程序编程接口（API）模型。 CUDA-X CUDA-X AI 是软件加速库的集合。这些库建立在 CUDA® （NVIDIA 的开创性并行编程模型）之上，提供对于深度学习、机器学习和高性能计算 (HPC) 必不可少的优化功能。这些库包括 cuDNN（用于加速深度学习基元）、cuML（用于加速数据科学工作流程和机器学习算法）、NVIDIA® TensorRT™（用于优化受训模型的推理性能）、cuDF（用于访问 pandas 之类的数据科学 API）、cuGraph（用于在图形上执行高性能分析），以及超过 13 个的其他库。 CUDA Core nvidia GPU的处理器核心或叫像素管道。相同架构下的GPU，越多的CUDA Core代表着越高的性能。什么是架构，有哪些架构，本文有详细说明。GPU架构与CUDA Core的数量一样重要，更先进的架构的加速卡，不一定比用了老架构的卡更快，比如T4就不如V100。 Stream Processor AMD家的“CUDA Core”。不能将 CUDA Core和Stream Processer等同起来，两者功能相似，但是不可比。 Tensor Core Nvidia在其Volta架构中引入了Tensor Core这一特殊功能单元，使得Tesla V100的峰值吞吐率可以达到Tesla P100 32位浮点吞吐率的12倍，开发者也可以利用混合精度在不牺牲精度的情况下达到更高的吞吐率。 自Volta架构首次推出 Tensor Core 技术到目前（07）的Hoper架构以来，NVIDIA GPU 的峰值性能提高了 60 倍。 TFFLOPS 一个TFLOPS（teraFLOPS）等于每秒一万亿（=10^12）次的浮点运算。 NVLINK 高速互联技术，2016年随Pascal GP100 GPU和Tesla P100加速器一起推出。 与PCIe互联技术相比，可以提供GPU之间GPU和CPU之间更高速的传输性能。 GDDR6 第六版图形用双倍资料传输率（Graphics Double Data Rate, version 6，简称GDDR6）是一种高带宽的显示存储器标准，用于显卡、游戏终端以及高性能运算上。 各个Tensor Core架构支持的精度类型 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://&lt;username&gt;.github.io/posts/NVIDIA%E7%94%9F%E6%80%81%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D/" /><meta property="article:section" content="posts" />


<title>Nvidia生态中的一些常见概念介绍 | Hugo Book</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css" integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz&#43;OQteg=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.df7d0f4a1e117d4e2c84814e9ebec0062101e62e43fd57cb78ff3fb7c8c738b8.js" integrity="sha256-330PSh4RfU4shIFOnr7ABiEB5i5D/VfLeP8/t8jHOLg=" crossorigin="anonymous"></script>

  <script defer src="/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js" integrity="sha256-b2&#43;Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC&#43;NdcPIvZhzk=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Hugo Book</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>



  



  
    
  
    
  



<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex justify-between">
      <a role="button" class="flex align-center">
        <img src="/svg/translate.svg" class="book-icon" alt="Languages" />
        English
      </a>
    </label>

    <ul>
      
      <li>
        <a href="https://%3cusername%3e.github.io/ru/">
          Russian
        </a>
      </li>
      
      <li>
        <a href="https://%3cusername%3e.github.io/zh/">
          Chinese
        </a>
      </li>
      
    </ul>
  </li>
</ul>











  












  
<ul>
  
  <li>
    <a href="/posts/"  >
        Blog
      </a>
  </li>
  
  <li>
    <a href="https://github.com/alex-shpak/hugo-book"  target="_blank" rel="noopener">
        Github
      </a>
  </li>
  
  <li>
    <a href="https://themes.gohugo.io/hugo-book/"  target="_blank" rel="noopener">
        Hugo Themes
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Nvidia生态中的一些常见概念介绍</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#nvidia生态中的一些常见概念介绍">NVIDIA生态中的一些常见概念介绍</a>
      <ul>
        <li><a href="#1-背景">1. 背景</a></li>
        <li><a href="#2-概念区分">2. 概念区分</a></li>
        <li><a href="#3-有哪些架构">3. 有哪些架构</a></li>
        <li><a href="#4-有哪些产品">4. 有哪些产品</a></li>
        <li><a href="#5-几张常见卡的算力比较">5. 几张常见卡的算力比较</a></li>
        <li><a href="#6-更多介绍">6. 更多介绍</a>
          <ul>
            <li><a href="#cuda-x">CUDA-X：</a></li>
            <li><a href="#cuda-x以外">CUDA-X以外：</a></li>
          </ul>
        </li>
        <li><a href="#7-参考链接">7. 参考链接</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
<article class="markdown">
  <h1>
    <a href="/posts/NVIDIA%E7%94%9F%E6%80%81%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%BB%8D/">Nvidia生态中的一些常见概念介绍</a>
  </h1>
  


  

  



<h1 id="nvidia生态中的一些常见概念介绍">
  NVIDIA生态中的一些常见概念介绍
  <a class="anchor" href="#nvidia%e7%94%9f%e6%80%81%e4%b8%ad%e7%9a%84%e4%b8%80%e4%ba%9b%e5%b8%b8%e8%a7%81%e6%a6%82%e5%bf%b5%e4%bb%8b%e7%bb%8d">#</a>
</h1>
<h2 id="1-背景">
  1. 背景
  <a class="anchor" href="#1-%e8%83%8c%e6%99%af">#</a>
</h2>
<p>对NVIDIA全系产品常见概念进行简单梳理，以便了解各架构发展历程、显卡算力及引擎开发可能涉及的库。</p>
<h2 id="2-概念区分">
  2. 概念区分
  <a class="anchor" href="#2-%e6%a6%82%e5%bf%b5%e5%8c%ba%e5%88%86">#</a>
</h2>
<ul>
<li>概念区分
<ul>
<li>加速卡，Product级别概念，如V100卡，3080Ti卡</li>
<li>GPU，Chip级别概念，如V100卡搭载的是GV100的GPU芯片</li>
</ul>
</li>
<li>CUDA
<ul>
<li>英伟达的并行计算平台和应用程序编程接口（API）模型。</li>
</ul>
</li>
<li>CUDA-X
<ul>
<li>CUDA-X AI 是软件加速库的集合。这些库建立在 CUDA® （NVIDIA 的开创性并行编程模型）之上，提供对于深度学习、机器学习和高性能计算 (HPC) 必不可少的优化功能。这些库包括 cuDNN（用于加速深度学习基元）、cuML（用于加速数据科学工作流程和机器学习算法）、NVIDIA® TensorRT™（用于优化受训模型的推理性能）、cuDF（用于访问 pandas 之类的数据科学 API）、cuGraph（用于在图形上执行高性能分析），以及超过 13 个的其他库。</li>
</ul>
</li>
<li>CUDA Core
<ul>
<li>nvidia GPU的处理器核心或叫像素管道。相同架构下的GPU，越多的CUDA Core代表着越高的性能。什么是架构，有哪些架构，本文有详细说明。GPU架构与CUDA Core的数量一样重要，更先进的架构的加速卡，不一定比用了老架构的卡更快，比如T4就不如V100。</li>
</ul>
</li>
<li>Stream Processor
<ul>
<li>AMD家的“CUDA Core”。不能将 CUDA Core和Stream Processer等同起来，两者功能相似，但是不可比。</li>
</ul>
</li>
<li>Tensor Core
<ul>
<li>Nvidia在其Volta架构中引入了Tensor Core这一特殊功能单元，使得Tesla V100的峰值吞吐率可以达到Tesla P100 32位浮点吞吐率的12倍，开发者也可以利用混合精度在不牺牲精度的情况下达到更高的吞吐率。</li>
<li>自Volta架构首次推出 Tensor Core 技术到目前（07）的Hoper架构以来，NVIDIA GPU 的峰值性能提高了 60 倍。</li>
</ul>
</li>
<li>TFFLOPS
<ul>
<li>一个TFLOPS（teraFLOPS）等于每秒一万亿（=10^12）次的浮点运算。</li>
</ul>
</li>
<li>NVLINK
<ul>
<li>高速互联技术，2016年随Pascal GP100 GPU和Tesla P100加速器一起推出。</li>
<li>与PCIe互联技术相比，可以提供GPU之间GPU和CPU之间更高速的传输性能。</li>
</ul>
</li>
<li>GDDR6
<ul>
<li>第六版图形用双倍资料传输率（Graphics Double Data Rate, version 6，简称GDDR6）是一种高带宽的显示存储器标准，用于显卡、游戏终端以及高性能运算上。</li>
</ul>
</li>
<li>各个Tensor Core架构支持的精度类型</li>
</ul>
<h2 id="3-有哪些架构">
  3. 有哪些架构
  <a class="anchor" href="#3-%e6%9c%89%e5%93%aa%e4%ba%9b%e6%9e%b6%e6%9e%84">#</a>
</h2>
<ul>
<li>NVIDIA Kepler架构
<ul>
<li>对应GPU芯片如：GK180</li>
<li>对应加速器卡如：Tesla K40</li>
</ul>
</li>
<li>NVIDIA Maxwell架构
<ul>
<li>对应GPU芯片如：GM200</li>
<li>对应加速器卡如：Tesla M40</li>
</ul>
</li>
<li>NVIDIA Pascal™架构
<ul>
<li>对应GPU芯片如：GP100</li>
<li>对应加速器卡如：Tesla P100</li>
</ul>
</li>
<li>Volta架构
<ul>
<li>对应GPU芯片如：GV100</li>
<li>对应加速器卡如：Tesla V100</li>
<li>NVIDIA® CUDA®内核和 Tensor 内核搭配使用</li>
<li>NVIDIA Volta™ 是第一代tensor core架构。专为深度学习而设计，通过 FP16 和 FP32 下的混合精度矩阵乘法提供了突破性的性能 – 与 NVIDIA Pascal 相比，用于训练的峰值 teraFLOPS (TFLOPS) 性能提升了高达 12 倍，用于推理的峰值 TFLOPS 性能提升了高达 6 倍。这项关键功能使 Volta 提供了比 Pascal 高 3 倍的训练和推理性能。</li>
</ul>
</li>
<li>Turing架构
<ul>
<li>对应GPU芯片如：TU104</li>
<li>对应加速器卡如：Tesla T4</li>
<li>NVIDIA Turing™架构是第二代Tensor Core架构，能进行多精度计算，可实现高效的 AI 推理。Turing Tensor Core 提供了一系列用于深度学习训练和推理的精度（从 FP32 到 FP16 再到 INT8 和 INT4），性能大大超过 NVIDIA Pascal™ GPU。</li>
</ul>
</li>
<li>NVIDIA Ampere架构
<ul>
<li>对应GPU芯片如：GA100</li>
<li>对应加速器卡如：A100 PCIe</li>
<li>NVIDIA Ampere 架构 是第三代Tensor Core架构。 基于先前的创新成果而构建，通过使用新的精度（TF32 和 FP64）来加速和简化 AI 采用，并将 Tensor Core 的强大功能扩展至 HPC。这些第三代 Tensor Core 支持 BFloat16、INT8 和 INT4，可为 AI 训练和推理创建高度通用的加速器。</li>
</ul>
</li>
<li>NVIDIA Hopper™ 架构
<ul>
<li>对应GPU芯片如：GH100</li>
<li>对应加速器卡如：H100 PCIe</li>
<li>H100架构全称NVIDIA Hopper™ 架构，是第四代Tensor Core架构，NVIDIA Hopper™ 架构利用 Transformer 引擎改进第四代 Tensor Core，该引擎使用新的 8 位浮点精度 (FP8)，可为万亿参数模型训练提供比 FP16 高 6 倍的性能。Hopper Tensor Core 使用 TF32、FP64、FP16 和 INT8 精度，将性能提升 3 倍，能够加速处理各种工作负载。</li>
</ul>
</li>
<li>下一代架构 Lovelace
<ul>
<li>预计将在2022年RTX系列新卡正式推出</li>
</ul>
</li>
<li>架构更迭时间线
<ul>
<li>2010-2016 Fermi</li>
<li>2010-2013 VLIW Vec4</li>
<li>2010-2016 Fermi 2.0</li>
<li>2012-2018 Kepler</li>
<li>2013-2015 Kepler 2.0</li>
<li>2014-2017 Maxwell</li>
<li>2014-2019 Maxwell 2.0</li>
<li>2016-2021 Pascal</li>
<li>2017-2020 Volta</li>
<li>2018-2022 Turing</li>
<li>2020-2022 Ampere</li>
<li>2022 Hopper</li>
<li>2022-2023 Lovelace</li>
</ul>
</li>
</ul>
<h2 id="4-有哪些产品">
  4. 有哪些产品
  <a class="anchor" href="#4-%e6%9c%89%e5%93%aa%e4%ba%9b%e4%ba%a7%e5%93%81">#</a>
</h2>
<p>根据
  <a href="https://developer.nvidia.com/cuda-gpus#collapseOne">NVIDIA官网</a>的信息和自己的调研，个人从两个角度进行了分类，仅做了解用，不专业地方见谅。</p>
<ul>
<li>按照工作场景分类
<ul>
<li>
<p>工作站</p>
<ul>
<li>Tesla K40、Tesla K80</li>
</ul>
</li>
<li>
<p>数据中心</p>
<ul>
<li>Tesla K、M、P、T、A系列</li>
</ul>
</li>
<li>
<p>移动设备</p>
<ul>
<li>
<p>不一一列举，详见</p>
<p>
  <a href="https://developer.nvidia.com/cuda-gpus#collapseOne">官网</a></p>
</li>
</ul>
</li>
<li>
<p>桌面</p>
<ul>
<li>
<p>不一一列举，详见</p>
<p>
  <a href="https://developer.nvidia.com/cuda-gpus#collapseOne">官网</a></p>
</li>
</ul>
</li>
<li>
<p>笔记本</p>
<ul>
<li>
<p>不一一列举，详见</p>
<p>
  <a href="https://developer.nvidia.com/cuda-gpus#collapseOne">官网</a></p>
</li>
</ul>
</li>
<li>
<p>按照使用场景分类</p>
<ul>
<li>计算卡
<ul>
<li>Tesla(特斯拉)：主要用于服务器高性能电脑运算，Tesla一般是不设计外接接口，主要是辅助CPU去计算所需应用，常应用于研究物理、生化和深度学习等领域；Tesla与Nvidia Grid系列产品全部由NVIDIA原厂设计和生产，产品品质和服务都更有保障，毕竟应用于高科技领域，Nvidia肯定是将技术核心掌握在手中。</li>
</ul>
</li>
<li>图形卡
<ul>
<li>Quadro系列：是面向各种3D设计软件、CAD软件、工业模型设计软件而推出。授权生产的厂商非常有限，一般比GeForce的显存更大，可靠性更高。欧美地区由美国的必恩威(PNY)负责，而台湾的丽台(Leadtek)负责欧亚太地区的销售。艾尔莎日本(Elsa Japan)则仅仅在日本有销售的权利。这三家公司互不进入对方所在的市场，所以我们见到的全新Quadro显卡都是属于丽台生产的。</li>
<li>Quadro NVS：属于Quadro产品线中的一个系列，用于多显示商用显卡，可用多个虚拟桌面显示，协助企业安装部署的多种预设设定。</li>
</ul>
</li>
<li>消费级显卡
<ul>
<li>GeForce系列：面向消费者的图形处理产品，主要用于台式电脑和笔记本电脑；主要由第三方厂商生产，而且还区分为采用原厂设计的公版型号和厂商自行设计的非公版型号，其产品的稳定性可能也因不同厂商的设计和工艺水平存在差异。</li>
</ul>
</li>
<li>其他
<ul>
<li>Nvidia Grid：Nvidia用于图形虚拟化的一套硬件和服务，可以根据用户需求分配使用量，这意味着，多名用户可以共享单一 GPU。</li>
<li>Tegra：用于移动设备的芯片系列，常应用于手机及平板电脑等移动端使用；Tegra系列产品由NVIDIA与微软合作设计和生产。</li>
</ul>
</li>
<li>题外话：矿卡
<ul>
<li>主流矿卡也与时俱进，一般是中高端消费级显卡。</li>
<li>24小时不间断的运行。通常矿卡可以使用半年以上，具体要看用的矿卡的型号和用法。矿卡使用6个月的性能降低是比较小的，但使用九个月以后它的显存频率就会降低，之后再继续使用就容易坏，如果性能稍强的矿卡能用时间就会更久，但一般不会超过一年半。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="5-几张常见卡的算力比较">
  5. 几张常见卡的算力比较
  <a class="anchor" href="#5-%e5%87%a0%e5%bc%a0%e5%b8%b8%e8%a7%81%e5%8d%a1%e7%9a%84%e7%ae%97%e5%8a%9b%e6%af%94%e8%be%83">#</a>
</h2>
<h2 id="6-更多介绍">
  6. 更多介绍
  <a class="anchor" href="#6-%e6%9b%b4%e5%a4%9a%e4%bb%8b%e7%bb%8d">#</a>
</h2>
<h3 id="cuda-x">
  CUDA-X：
  <a class="anchor" href="#cuda-x">#</a>
</h3>
<ul>
<li>
<p>NVIDIA TensorRT</p>
<ul>
<li>NVIDIA® TensorRT™ 是一款高性能推理平台，在充分发挥 NVIDIA Tensor Core GPU 的强大功能方面发挥着关键作用。与仅使用 CPU 的平台相比，TensorRT 可使吞吐量提升高达 40 倍，同时还可更大限度地降低延迟。使用 TensorRT，您可以从任何框架入手，并在生产环境中快速优化、验证和部署经过训练的神经网络。TensorRT 还可在 NVIDIA NGC 目录上使用。</li>
</ul>
</li>
<li>
<p>NVIDIA TRITON</p>
<ul>
<li>NVIDIA Triton 推理服务器（以前称为 TensorRT 推理服务器）是一款开源软件，可简化深度学习模型在生产环境中的部署。借助 Triton 推理服务器，团队可以通过任何框架（TensorFlow、PyTorch、TensorRT Plan、Caffe、MXNet 或自定义框架），在任何基于 GPU 或 CPU 的基础设施上从本地存储、Google 云端平台或 AWS S3 部署经过训练的 AI 模型。它可在单个 GPU 上同时运行多个模型，以更大限度地提高利用率，并可与 Kubernetes 集成以用于编排、指标和自动扩展。</li>
</ul>
</li>
<li>
<p>cuDNN</p>
<ul>
<li>NVIDIA CUDA® 深度神经网络库 (cuDNN) 是一个 GPU 加速的深度神经网络基元库，能够以高度优化的方式实现标准例程（如前向和反向卷积、池化层、归一化和激活层）。</li>
</ul>
</li>
<li>
<p>NCCL</p>
<ul>
<li>NCCL是Nvidia Collective multi-GPU Communication Library的简称，它是一个实现多GPU的collective communication通信（all-gather, reduce, broadcast）库，Nvidia做了很多优化，以在PCIe、Nvlink、InfiniBand上实现较高的通信速度。</li>
</ul>
</li>
<li>
<p>Cublas</p>
<ul>
<li>cuBLAS是CUDA专门用来解决线性代数运算的库，分为三个级别：Lev1向量乘向量、Lev2矩阵乘向量、Lev3矩阵乘矩阵。CUDA自带cublas，无需额外安装。</li>
<li>cuDnn是CUDA专门用来解决神经网络加速的库，速度快、内存开销低。cuDNN可以方便的集成到更高级别的机器学习框架中(PyTorch、Tensorflow)，支持常用神经网络组件，需要独立安装。</li>
</ul>
</li>
<li>
<p>更多详见：</p>
<p>
  <a href="https://developer.nvidia.com/gpu-accelerated-libraries">NVIDIA CUDA-X | NVIDIA Developer</a></p>
</li>
</ul>
<h3 id="cuda-x以外">
  CUDA-X以外：
  <a class="anchor" href="#cuda-x%e4%bb%a5%e5%a4%96">#</a>
</h3>
<ul>
<li>OpenCL
<ul>
<li>是由苹果（Apple）公司发起，业界众多著名厂商共同制作的面向异构系统通用目的并行编程的开放式、免费标准，也是一个统一的编程环境。CUDA和OpenCL的关系并不是冲突关系，而是包容关系。CUDA C是一种高级语言，那些对硬件了解不多的非专业人士也能轻松上手；而OpenCL则是针对硬件的应用程序开发接口，它能给程序员更多对硬件的控制权，相应的上手及开发会比较难一些。</li>
</ul>
</li>
</ul>
<h2 id="7-参考链接">
  7. 参考链接
  <a class="anchor" href="#7-%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5">#</a>
</h2>
<ul>
<li></li>
</ul>
<pre><code>[NVIDIA 技术和 GPU 架构 英伟达](https://www.nvidia.cn/technologies/)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[CUDA GPUs算力一览](https://developer.nvidia.com/cuda-gpus#collapseOne)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[CUDA Cores vs Stream Processors Explained](https://graphicscardhub.com/cuda-cores-vs-stream-processors/)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[Nvidia Turing vs Volta v Pascal GPU Architecture Comparison |夏天的风的博客](http://xiaqunfeng.cc/2019/12/06/turing-vs-volta-v-pascal/)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[NVIDIA GM200 GPU Specs | TechPowerUp GPU Database](https://www.techpowerup.com/gpu-specs/nvidia-gm200.g772)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[GPU Database | TechPowerUp](https://www.techpowerup.com/gpu-specs/)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[GeForce和Quadro图形卡有什么区别？ - 产品评测](http://www.hp168.com/news_view.aspx?id=706&amp;nid=2&amp;typeid=50027&amp;IsActiveTarget=True)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[NVIDIA CUDA-X | NVIDIA Developer](https://developer.nvidia.com/gpu-accelerated-libraries)
</code></pre>
<ul>
<li></li>
</ul>
<pre><code>[NVIDIA显卡GeForce、Tesla、Quadro、Tegra、Tesla、等详细介绍](https://blog.csdn.net/weixin_39883440/article/details/111694586)</code></pre>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">




  <div>
    <a class="flex align-center" href="https://github.com/alex-shpak/hugo-book/edit/main/exampleSite/content/posts/NVIDIA%e7%94%9f%e6%80%81%e4%b8%ad%e7%9a%84%e4%b8%80%e4%ba%9b%e5%b8%b8%e8%a7%81%e6%a6%82%e5%bf%b5%e4%bb%8b%e7%bb%8d.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#nvidia生态中的一些常见概念介绍">NVIDIA生态中的一些常见概念介绍</a>
      <ul>
        <li><a href="#1-背景">1. 背景</a></li>
        <li><a href="#2-概念区分">2. 概念区分</a></li>
        <li><a href="#3-有哪些架构">3. 有哪些架构</a></li>
        <li><a href="#4-有哪些产品">4. 有哪些产品</a></li>
        <li><a href="#5-几张常见卡的算力比较">5. 几张常见卡的算力比较</a></li>
        <li><a href="#6-更多介绍">6. 更多介绍</a>
          <ul>
            <li><a href="#cuda-x">CUDA-X：</a></li>
            <li><a href="#cuda-x以外">CUDA-X以外：</a></li>
          </ul>
        </li>
        <li><a href="#7-参考链接">7. 参考链接</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












